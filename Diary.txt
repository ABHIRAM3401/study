Day 1 : 23-04-2005
    started learning about open cv in yt channel https://youtu.be/eDIj5LuIL4A?si=aqz3QyjUPCYaw_5z
    https://chatgpt.com/c/68079c7e-78c0-8003-afdf-9eab3142d3fc this link only opens with my mail , for you guys i will give the shared link

    made some manipulations in imread() function
    USE OF RESIZE:
        First I got a problem , the window or frame size is too large , because of that i cannot visualize the entire image .
        So i have changed the image size by using the "cv2.resize(img,(widht,height))" function , later i have tried different sizes 
        to visualize that image . As it is a square image of size 1024 , i have changed its size to 800

        CUSTOMIZED WINDOW CREATION:
        my question to gpt : so the first paramter of imshow is not just a random name of the window ,we can create multile named windows and we can use those different windows based on our requirement
        the ans by gpt: Exactly! 💡 You nailed it.

        https://chatgpt.com/c/6808e059-2914-8003-89e8-50b674a92a88   https://chatgpt.com/share/6808e92b-9978-8003-ae9f-c85a1e6c3930

        surprise , chat gpt has given me some other code for the above problem and that made me to dive deeper into naming windows and 
        the actual purpose of the first paramter of imshow('window_name',flag) and different flags in cv2.namedWindow().

            cv2.namedWindow('My Window', cv2.WINDOW_NORMAL)
            cv2.resizeWindow('My Window', 800, 600)
            cv2.imshow('My Window', img)

        by using the cv2.namedWindow() fucntion we can create a customized window with the below features with the help of different flags
        here we can create multiple windows of different flags based on our purpose.
        Flag	            Description
        cv2.WINDOW_NORMAL	Allows the user to resize the window.
        cv2.WINDOW_AUTOSIZE	Default. Window size matches image size, and you cannot resize it.
        cv2.WINDOW_FULLSCREEN	Displays window in fullscreen mode (depends on OS support).
        cv2.WINDOW_FREERATIO	Allows resizing the image freely without keeping aspect ratio.
        cv2.WINDOW_KEEPRATIO	Resizes image but keeps aspect ratio. Usually used with resizeWindow().
        
        we can adust the size of the window by using the cv2.resizeWindow('window_name',width,height)
        THIS ALL STARTED BECAUSE OF A SIMPLE PROBLEM and that made to learn some intresting things.

        LATER TRIED NORMAL AND KEEPRATIO FLAGS
        if we just create a window and if we are not using it for displaying any image , then an empty window is displayed on the screen
            cv2.imshow('actual',img)
            cv2.waitKey(3000)
            cv2.namedWindow('Normal window', cv2.WINDOW_NORMAL)
            cv2.resizeWindow('Normal window', 800, 300)

            cv2.namedWindow('Keepratio',cv2.WINDOW_KEEPRATIO)
            cv2.resizeWindow('Keepratio',400,550)

            cv2.imshow('Normal window', img)
            cv2.waitKey(3000)
            # cv2.imshow('keepratio', img)
            # cv2.waitKey(0)
            cv2.destroyAllWindows()

            in this code , i have commented the code for imshow('keepratio') so the image doesn't dsplayed but as i have created the window , 
            it displays an empty window on my screen ,
            sorry to say this but , even if i use an image to show with that window an extra empty window is displaying , i need to check about that later
Day 2 : 25-04-2025
    https://chatgpt.com/c/680a6386-48d8-8003-a7e9-0f192bbfcb51
    Video reading :
        "cv2.VideoCapture" This is a class in OpenCV used to handle video streams — from a file, a webcam, or even a network stream.
        OpenCV attempts to open the video file located at that path.
        If successful, it creates a VideoCapture object which acts like a "video reader."
        This object lets you read the video one frame at a time using .read().

        what does videoCapture returns  i.e. what will be stored in the video variable?
            video will store a cv2.VideoCapture object, which is basically a handler (or interface) that OpenCV uses to interact with the video.
            print(type(video)) --> <class 'cv2.VideoCapture'>

        ret, frame = video.read()    
            ret is the return status — like saying "Did this operation succeed? 
            frame is the actual data returned.

        🔓 What does .release() do?
            It releases the resources associated with the cv2.VideoCapture object.
            This means:
            If it's a video file, OpenCV closes the file.If it's a webcam or external camera, OpenCV releases the hardware (so other apps can use it).
            Prevents memory leaks, resource locks, and weird behavior if you open multiple streams.

        🧽 Why it's important:
            If you don’t call .release():
            Your program might keep the file open.
            You might lock your webcam, and other apps (like Zoom) won't be able to use it.
            Over time, it can lead to resource exhaustion if you're working with many video streams.
        🧠 Think of it like:
            If cv2.VideoCapture is you checking out a book, then release() is returning the book to the library once you’re done.

Day 3 : 27-04-2025
    https://chatgpt.com/c/680dfc81-9af0-8003-81cf-cf63b02b3166
    Return value of waitKey():
        "
        cv2.imshow('image',resized)
        b = cv2.waitKey(5000) 
        print(b)
        what will be the output of that and what does cv2.waitKey() returns
        
        "
        If you press a key during those 5 seconds, cv2.waitKey(5000) will return the ASCII code of the key you pressed.
        If no key is pressed during the 5 seconds, cv2.waitKey(5000) will return -1.

        " and when press any key why the window is closing rather than waiting for 5 seconds"
        Ah, great observation! Here's the catch:
        In OpenCV, the behavior of cv2.waitKey() is a little subtle . cv2.waitKey(delay) waits up to delay milliseconds for a key press.
        If you press a key before the delay finishes, cv2.waitKey() immediately returns, and the program continues — it doesn't continue waiting after a key is pressed.
        ✅ If no key is pressed, it will wait full 5 seconds.
        ✅ If any key is pressed, it stops waiting immediately.


        " or we can select any particular key wiht 0xFF ord('q')what about this"
        Exactly, you're thinking in the right direction! 🔥 Let’s explain it properly:
        cv2.waitKey(0) waits forever for any key. & 0xFF ensures you get a clean 8-bit keycode.
        ord('q') gives you the numeric code for 'q'. Then you can do things depending on which key the user pressed!

        If you don't press anything during 5 seconds, cv2.waitKey(5000) returns -1 (after masking with & 0xFF, it becomes 255 — small technical detail I’ll explain below).
    USE OF WEBCAM :
        Instead of giving the video path for the videoCapture if we give input as a digit (generally 0 as our main webcam) it activates the webcam and we can get frames from it . here we dont need the ret vlaue because (find the reason in code of webcam ) .


            TRYING TO CONNECT MY MOBILE CAM TO LAPTOP BUT THAT IS NOT POSSIBLE WIHTOUT A DEDICATED DRIVER OR SOFTWARE BECAUSE WE CONNECT OUR 
            MOBILE TO LAPTOP IN ANY OF THESE 3 MODES 1.  CHARGING ONLY , 2 .  Media/Files Transfer Protocol (MTP) , 3  .Picture Transfer 
            Protocol (PTP)  AND ANY OF THEM DON'T HAVE ACCESS TO MY MOBILE CAMERA 

                https://gemini.google.com/app/1396e3c12268a319?hl=en-IN
                
                Different Protocols: Standard webcams communicate using specific video protocols that operating systems readily understand. Mobile phone cameras, when connected via USB, typically operate in different modes like Media Transfer Protocol (MTP) for file transfer or Picture Transfer Protocol (PTP) for photo access. These protocols don't inherently provide a live video stream in the format expected by webcam applications.

                Driver Requirements: Webcams have specific drivers that allow the operating system and applications to interact with their video and control functionalities. When you connect a phone via USB in MTP/PTP mode, it usually uses generic drivers for file access, not the specialized drivers needed for live video streaming as a webcam.   

                Virtualization Layer: Software like DroidCam acts as a crucial intermediary. It captures the video stream from your phone's camera and then creates a virtual webcam device on your computer. This virtual device adheres to the standard webcam protocols and has its own drivers, allowing applications like your OpenCV script or meeting software to recognize and use it.
 

Day 4 : 02-05-2025
    COLOUR SPACES  https://chatgpt.com/c/6814c37b-fbe4-8003-aefc-dfe06011c0f3
        cvtColor(img,cv2.COLOR_BGR2RGB)
        the nature image looks cool after converting it from  bgr  to rgb
        COLOR_BGR2RGB , 2HSV , 2GRAY are some of the common color spaces in opencv
DAY 5 : 13-05-2025
        https://chatgpt.com/c/68231f2d-9c80-8003-9f1a-7257aa2f14c1
        LONG TIME NO SEE 
        yeah , my summer vacation has started and quite busy with marriages and now i have moved to hyd from my village to learn car driving 
        
        ignoring this gap lets get into the topic

        I was just revising this cv2 repo and listened the color spaces topic again.
        As i have an idea about how the color images turn into gray scale by multiplying the luminance weights , 
        At this point of time an idea striked on my mind , in present days we are seeing the old black and white movies in color format but how they are doing that , are they reconstructing the actual color image from the single graysclae value ,
        this made me to think on the topic conversion of gray scale to color 
        I have done some experiment on converting the gray to color (line 30 in color_spaces.py)
        just i have converted the image to rgb then gray and again back to rgb 
        suprisingly i got the grayscale image at last in the rgb format
        i.e. https://chatgpt.com/c/68231f2d-9c80-8003-9f1a-7257aa2f14c1

        When you need to use grayscale images in contexts that require 3-channel input (e.g., some CNN models). (search for this in the chat)

DAY 6 : 17-05-2025
    BLURING https://chatgpt.com/c/68235b19-baf0-8003-a7ae-6916548ba5bb
        here i have learned about the effect of different kernel sizes in bluring , and the border flags(which you can see in the chat ) of basic blur function cv2.blur(img , (k_size, k_size)) , and upon changing the k_size , the intensity of bluring changes .
        here a doubt has raised in my mind , what if i blur the img which already blurred , and i didn't observed much changes between those 2 pics , then i asked gpt , but the ans from gpt felt unsatisfied for me , and after thinking for couple of minutes , i got an idea to print the pixel values of original , blur3 and blur33 images , then i came to know about actually what happened ,
            when the original image is blured with 3,3 kerenl we got an image blur3 , in blur3 the neigbhouring pixels are nearer compared to that of original image , so when we blur the image again (i.e bluring blur3 again with 3,3 kernel ) we get blur33 , as the pixels are nearer  , the average value will be nearer , 
            [ 98 102  97] [105 109 104] [108 111 107] (original , blur3 , blur33 )
            look at these values , 105 and 108 are closer but 105 is a bit far from 98(the pixel of orignal image )

DAY 7 :23-05-2025
    TYPES OF BLURING https://chatgpt.com/c/6830218a-ef18-8003-9e54-bb0c2b13b4da
    share link https://chatgpt.com/share/68303a24-95b8-8003-bc28-91e33c6f851c
    different types of bluring , mainly there will be 4 but in the video he taught me 3 types , they are 
    classical blur cv2.blur(img,(k_size,k_size)), gaussian blur cv2.GaussinaBlur(img , (k_size,k_size),standard_deviation) ,
    median blur cv2.medianBlur(img,k_size)

    all these are used to blur an image but each have their own importance and application . the classical blur takes the average of all pixels 
    in the kernel and the kernel weigts are equal to 1/(k^2) ,but in case of gaussian blur we give much importance to the nearer pixels compared
    to pixels which are far from the center. so the weights in the kernel are different and thy are calculated by a formual . and we have the 
    standard standard_deviation parameter in gaussian blur , read the gpt chat to get know about standard deviation usage in gaussian blur.
    now come to one of the importatn bluring techinique , i.e. median bluring , here we dont have any weights in the kernel , we take the direct values from the image and sort the values in kernel and takes the middle one , that is we have calculated the median here .
    
    medain blur is used to reduce the salt-pepper nosie (salt -> white -> pixel value 255 , pepper -> black -> pixel value 0) , which is mostly 
    observed in gray scales images , we may have either 0 or 255 as the  pixel value and that causes some noise in the image
    
    the median blur can also be used to reduce the noise in color image ([255,255,255] , [0,0,0] [b,g,r]) , but here we take each channel separately as a grayscale , then we compute the median for each channel and rearrange them as bgr or rgb again .

    if we apply gaussian or classical blur for a salt-pepper image , then we can see "smear effect" which cause some disturbance in the image, 
    because the values in salt pepper image as extreme values (0 or 255) , so when we are calculating the average those extreme values can chagne the value (see in chat for clear understanding .)

DAY 8 01-26-2025
    READING DOCUMENTATION
    https://docs.opencv.org/4.x/index.html
    https://docs.opencv.org/4.x/db/deb/tutorial_display_image.html
    https://chatgpt.com/c/683bdf7e-4238-8003-98a9-6d6a0b7788eb

    actually i was watching the tutoroial , the THRESHOLD lesson , but suddenly a thought striked my mind to watch the actual documentation of OpenCV
    so , i just googled it and surpried by seeing  a thing which is not included in the youtube tutorial(to be honset we cannot learn everything in a day or in a month , every thing takes tiem and we need to wati)
    that is , the flags for imread() function , so i was eager to test them and i did

    🏁 Flags for cv2.imread()
    Flag	                 Value	         Description
    cv2.IMREAD_COLOR	      1	        Loads the image in color. Any transparency (alpha channel) is ignored.
    cv2.IMREAD_GRAYSCALE	  0	        Loads image in grayscale (1 channel).
    cv2.IMREAD_UNCHANGED	 -1	        Loads image as-is (including alpha channel if present).
    cv2.IMREAD_ANYCOLOR       4	        Loads image in any possible color format.
    cv2.IMREAD_ANYDEPTH	      2	        Loads image with original bit depth, if possible.
    cv2.IMREAD_REDUCED_COLOR_2 17	    Loads a 1/2-sized color version of the image.
    cv2.IMREAD_REDUCED_COLOR_4	33	    Loads a 1/4-sized color version of the image.
    cv2.IMREAD_REDUCED_COLOR_8	65	    Loads a 1/8-sized color version of the image.
    cv2.IMREAD_REDUCED_GRAYSCALE_2	16	Loads a 1/2-sized grayscale version.
    cv2.IMREAD_REDUCED_GRAYSCALE_4	32	Loads a 1/4-sized grayscale version.
    cv2.IMREAD_REDUCED_GRAYSCALE_8	64	Loads a 1/8-sized grayscale version.
    cv2.IMREAD_LOAD_GDAL	         8	Loads image using GDAL driver (for geospatial data). 